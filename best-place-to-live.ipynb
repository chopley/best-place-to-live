{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps,os,json\n",
    "import datetime\n",
    "import zillow\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle,polyline\n",
    "import klepto\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import xmltodict\n",
    "import pprint\n",
    "import pygsheets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class placesToLive():\n",
    "    \n",
    "    def __init__(self,address_list,destination):\n",
    "        self.cache = klepto.archives.file_archive('places_to_live', serialized=True)\n",
    "        self.cache_schools = klepto.archives.file_archive('schools', serialized=True)\n",
    "        self.cache_zillow = klepto.archives.file_archive('zillow', serialized=True)\n",
    "        self.cache.load()\n",
    "        self.cache_schools.load()\n",
    "        self.cache_zillow.load()\n",
    "        self.destination = destination\n",
    "        for item in address_list:\n",
    "            item['zip'] = str(item['zip'])\n",
    "            \n",
    "        self.cache['address_list'] = address_list\n",
    "        \n",
    "        self.api_key = os.environ.get('GOOGLE_API')\n",
    "        self.zillow_key = os.environ.get('ZILLOW_API')\n",
    "        self.school_digger_appID = os.environ.get('SCHOOLDIGGER_APPID')\n",
    "        self.school_digger_appKey = os.environ.get('SCHOOLDIGGER_APPKEY')\n",
    "        self.gmaps = googlemaps.Client(key=self.api_key)\n",
    "        \n",
    "        list_names = ['train_stations_list','bus_stations_list','travel_time_train_list',\n",
    "                      'travel_time_bus_list','drive_time_list','walk_time_list','address_details_list',\n",
    "                     'address_full_list','travel_transit_times','nearby_public_transport',\n",
    "                      'travel_to_transit_times','schools_data','district_data']\n",
    "        list_names_schools = ['schools']\n",
    "        \n",
    "        list_zillow = ['valuation_list']\n",
    "\n",
    "        #initiate the dicts in the cache if they don't currently exist\n",
    "        \n",
    "        for key in list_names:\n",
    "            if key not in self.cache.keys():\n",
    "                self.cache[key] = []\n",
    "                \n",
    "        for key in list_names_schools:\n",
    "            if key not in self.cache_schools.keys():\n",
    "                self.cache_schools[key] = []\n",
    "                \n",
    "        for key in list_zillow:\n",
    "            if key not in self.cache_zillow.keys():\n",
    "                self.cache_zillow[key] = []\n",
    "\n",
    "    \n",
    "    def get_time_of_travel(self,time_of_day,\n",
    "                       datetime_today,\n",
    "                       day_of_week):\n",
    "        # datetime_today = datetime.date.today()\n",
    "        #time of day e.g. 07:00\n",
    "        #day of week e.g. 1= Monday, 2= Tuesday etc.\n",
    "        next_day = datetime_today + datetime.timedelta(days=-datetime.datetime.today().weekday()+day_of_week, weeks=1)\n",
    "        date_string = str(next_day) + '-' + time_of_day\n",
    "        time_of_travel = datetime.datetime.strptime(date_string, '%Y-%m-%d-%H:%M')\n",
    "        return(time_of_travel)\n",
    "\n",
    "    def lookup_nearest_stations(self,address,\n",
    "                                house_location,\n",
    "                                nOpts,\n",
    "                               stationType):\n",
    "        matches = 0\n",
    "        for public_transport in self.cache['nearby_public_transport']:\n",
    "            if((address == public_transport['house_address']) & (stationType==public_transport['stationType'])):\n",
    "                matches = matches + 1\n",
    "        if(matches==0):\n",
    "            public_transport = self.gmaps.places_nearby(house_location,\n",
    "                                            rank_by=\"distance\",\n",
    "                                            name=stationType)\n",
    "            for i in range(0,nOpts):\n",
    "                value = {\n",
    "                     'house_address':address,\n",
    "                     'house_location':house_location,\n",
    "                     'public_transport_vicinity':public_transport['results'][i]['vicinity'],\n",
    "                     'types':public_transport['results'][i]['types'],\n",
    "                     'stationType':stationType,\n",
    "                     'public_transport_location' : (public_transport['results'][i]['geometry']['location']['lat'],public_transport['results'][i]['geometry']['location']['lng']),\n",
    "                    }\n",
    "                self.cache['nearby_public_transport'].append(value)\n",
    "        return(0)\n",
    "    \n",
    "    def lookup_travel_time_to_station(self,\n",
    "                        time_of_travel,\n",
    "                        type_of_transport):\n",
    "               \n",
    "        for station in self.cache['nearby_public_transport']:\n",
    "            matches = 0\n",
    "            for travel_to in self.cache['travel_to_transit_times']:\n",
    "                if((station['house_address']==travel_to['house_address']) & (station['public_transport_location']==travel_to['public_transport_location']) & (type_of_transport==travel_to['type_of_transport'])):\n",
    "                    matches = matches + 1\n",
    "                    \n",
    "            if(matches==0):\n",
    "                dd = self.gmaps.directions(station['house_location'],\n",
    "                                             station['public_transport_location'],\n",
    "                                             mode=type_of_transport,\n",
    "                                             departure_time=time_of_travel)\n",
    "                distance = (dd[0]['legs'][0]['distance']['text'])\n",
    "                duration = (dd[0]['legs'][0]['duration']['text'])\n",
    "                value = {'house_address':station['house_address'],\n",
    "                         'house_location':station['house_location'],\n",
    "                         'public_transport_location':station['public_transport_location'],\n",
    "                         'distance':distance,\n",
    "                         'duration':self.convert_google_duration_to_minutes(duration),\n",
    "                         'time_of_day' : time_of_travel,\n",
    "                         'type_of_transport' : type_of_transport,\n",
    "                         'type_of_station' : station['stationType']\n",
    "                        }\n",
    "                self.cache['travel_to_transit_times'].append(value)\n",
    "        return(0)\n",
    "    \n",
    "    def lookup_public_transit_travel_time(self,\n",
    "                                      final_destination,\n",
    "                                      time_of_travel):\n",
    "        for stn in self.cache['nearby_public_transport']:\n",
    "            start_station = stn['public_transport_vicinity']\n",
    "            matches = 0\n",
    "            for trip in self.cache['travel_transit_times']:\n",
    "                if((start_station == trip['station']) & (final_destination == trip['final_destination']) & (trip['time_of_day'] == time_of_travel)):           \n",
    "                    matches = matches + 1\n",
    "            if(matches == 0):\n",
    "                dd = self.gmaps.directions(stn['public_transport_location'],final_destination,mode='transit',departure_time=time_of_travel)\n",
    "                distance = (dd[0]['legs'][0]['distance']['text'])\n",
    "                duration = (dd[0]['legs'][0]['duration']['text'])\n",
    "                value = {\n",
    "                    'station_gps':stn['public_transport_location'],\n",
    "                    'station':stn['public_transport_vicinity'],\n",
    "                    'final_destination':final_destination,\n",
    "                    'distance': distance,\n",
    "                    'duration': self.convert_google_duration_to_minutes(duration),\n",
    "                    'time_of_day' : time_of_travel,\n",
    "                    'type_of_transport' : 'transit'\n",
    "                }\n",
    "                self.cache['travel_transit_times'].append(value)\n",
    "        return(0)\n",
    "\n",
    "    def convert_google_duration_to_minutes(self,string):\n",
    "        vals = [int(s) for s in string.split() if s.isdigit()]\n",
    "        if(len(vals)==3): #days+hours+minutes\n",
    "            train_duration_minutes = vals[0]*24*60+vals[1]*60+vals[2]\n",
    "        elif(len(vals)==2): #hours+minutes\n",
    "            train_duration_minutes = vals[0]*60+vals[1]\n",
    "        else:\n",
    "            train_duration_minutes = vals[0]\n",
    "        return(train_duration_minutes)\n",
    "\n",
    "    def travel_related_values(self):\n",
    "        for address_dict in self.cache['address_list']:\n",
    "            address = (address_dict['address'] + ' ' + address_dict['state'] + ' ' +address_dict['zip'])\n",
    "            if(address not in self.cache['address_full_list']):\n",
    "                address_gps_dict = self.gmaps.geocode(address)[0]['geometry']['location']\n",
    "                address_gps = (address_gps_dict['lat'],address_gps_dict['lng'])\n",
    "                self.lookup_nearest_stations(address,address_gps,5,'Train Station')\n",
    "                #self.lookup_nearest_stations(address,address_gps,5,'Bus Station')\n",
    "                self.lookup_public_transit_travel_time(self.destination,datetime.datetime(2019, 3, 28, 7, 0))\n",
    "                self.lookup_public_transit_travel_time(self.destination,datetime.datetime(2019, 3, 28, 7, 15))\n",
    "                self.lookup_public_transit_travel_time(self.destination,datetime.datetime(2019, 3, 28, 7, 30))\n",
    "                self.lookup_public_transit_travel_time(self.destination,datetime.datetime(2019, 3, 28, 7, 45))\n",
    "                self.lookup_travel_time_to_station(datetime.datetime(2019, 3, 28, 7, 0),'driving')\n",
    "                self.lookup_travel_time_to_station(datetime.datetime(2019, 3, 28, 7, 0),'walking')\n",
    "                self.cache['address_details_list'].append({'address':address,'address_gps':address_gps,'full_address':address_dict})\n",
    "                self.cache['address_full_list'].append(address)\n",
    "                self.cache.dump()\n",
    "        return(0)\n",
    "    \n",
    "    def school_related_values(self):\n",
    "        url = \"https://api.schooldigger.com/v1.1/districts\"\n",
    "        headers = {\"Accept\": \"application/json\"}\n",
    "        addresses = list(pd.DataFrame(self.cache['schools_data'])['address'])\n",
    "        for address in self.cache['address_details_list']:\n",
    "            if(address['address'] not in addresses):\n",
    "                payload = {'st': address['full_address']['state'], 'nearLatitude': address['address_gps'][0],'nearLongitude': address['address_gps'][1],'isInBoundaryOnly':'true','appID':self.school_digger_appID,'appKey': self.school_digger_appKey}\n",
    "                r = requests.get(url, headers=headers,params=payload)\n",
    "                self.cache['schools_data'].append({'address':address['address'],'schools_list':r.json()})\n",
    "        return(0)\n",
    "\n",
    "\n",
    "    def get_school_district(self):\n",
    "        #first we load the current database\n",
    "        self.cache_schools['address_details_list'] = self.cache['address_details_list']\n",
    "        print('getting school district')    \n",
    "        try:\n",
    "            for address in self.cache['address_details_list']:\n",
    "                print(address)\n",
    "                if(len(self.cache_schools['schools'])==0):\n",
    "                    print('No Schools yet loaded')\n",
    "                    house_gps_point = Point(address['address_gps'])\n",
    "                    print(address['address_gps'])\n",
    "                    for district in self.cache_schools['district_data']:\n",
    "                        for polyline_line in district['boundary']['polylineCollection']:\n",
    "                            polygon = polyline.decode(polyline_line['polylineOverlayEncodedPoints'])\n",
    "                            contains = (Polygon(polygon).contains(house_gps_point))\n",
    "                            if(contains):\n",
    "                                print('contains')\n",
    "                                self.cache_schools['schools'].append({'address':address['address'],'school':district})\n",
    "                                self.cache_schools.dump()\n",
    "\n",
    "                    payload = {'st': address['full_address']['state'], 'nearLatitude': address['address_gps'][0],'nearLongitude': address['address_gps'][1],'isInBoundaryOnly':'true','appID':self.school_digger_appID,'appKey': self.school_digger_appKey}\n",
    "                    r = requests.get(url, headers=headers,params=payload)\n",
    "                    new_district_id = r.json()['districtList'][0]['districtID']\n",
    "                    self.update_district_data(new_district_id)     \n",
    "                elif((address['address'] not in list(pd.DataFrame(self.cache_schools['schools'])['address'])) ):\n",
    "                    house_gps_point = Point(address['address_gps'])\n",
    "                    print(address['address_gps'])\n",
    "                    print('not in list')\n",
    "                    for district in self.cache_schools['district_data']:\n",
    "                        for polyline_line in district['boundary']['polylineCollection']:\n",
    "                            polygon = polyline.decode(polyline_line['polylineOverlayEncodedPoints'])\n",
    "                            contains = (Polygon(polygon).contains(house_gps_point))\n",
    "                            if(contains):\n",
    "                                print('contains')\n",
    "                                self.cache_schools['schools'].append({'address':address['address'],'school':district})\n",
    "                                self.cache_schools.dump()\n",
    "        except:\n",
    "            print('getting school data failed')\n",
    "                #print('querying the API',address['address_gps'][0],address['address_gps'][1])\n",
    "                #payload = {'st': address['full_address']['state'], 'nearLatitude': address['address_gps'][0],'nearLongitude': address['address_gps'][1],'isInBoundaryOnly':'true','appID':self.school_digger_appID,'appKey': self.school_digger_appKey}\n",
    "                #r = requests.get(url, headers=headers,params=payload)\n",
    "                #new_district_id = r.json()['districtList'][0]['districtID']\n",
    "                #self.update_district_data(new_district_id)                     \n",
    "        return(0)\n",
    "\n",
    "    def get_district_data_from_name(self,district_name,state):\n",
    "        print('getting district id for ' + district_name + state)\n",
    "        url = \"https://api.schooldigger.com/v1.1/districts/\"\n",
    "        headers = {\"Accept\": \"application/json\"}\n",
    "        payload = {'st':state,'q':district_name,'appID':self.school_digger_appID,'appKey': self.school_digger_appKey}\n",
    "        r_district = requests.get(url, headers=headers,params=payload)\n",
    "        print(r_district.json())\n",
    "        for district in r_district.json()['districtList']:\n",
    "            self.update_district_data(district['districtID'])\n",
    "        return(r_district.json())\n",
    "    \n",
    "    def update_district_data(self,district_id):\n",
    "        districtIDs = []\n",
    "        for district in self.cache_schools['district_data']:\n",
    "            districtIDs.append(district['districtID']) \n",
    "        if(district_id not in districtIDs):\n",
    "            print('updating district data ' + str(district_id))\n",
    "            url = \"https://api.schooldigger.com/v1.1/districts/\"+district_id\n",
    "            headers = {\"Accept\": \"application/json\"}\n",
    "            payload = {'appID':self.school_digger_appID,'appKey': self.school_digger_appKey}\n",
    "            r_district = requests.get(url, headers=headers,params=payload)\n",
    "            self.cache_schools['district_data'].append(r_district.json())\n",
    "            self.cache_schools.dump()\n",
    "        return(0)\n",
    "    \n",
    "    def check_cache(self,cache,field,check_val):\n",
    "        match = 0\n",
    "        for val in cache:\n",
    "            if val[field] == check_val:\n",
    "                match = match + 1\n",
    "        return(match)\n",
    "            \n",
    "            \n",
    "    def update_zillow_values(self):   \n",
    "        api = zillow.ValuationApi()\n",
    "        zillow_data_list = []\n",
    "        for home in self.cache['address_details_list']:\n",
    "            if((self.check_cache(self.cache_zillow['valuation_list'],'address',home['address']))==0):\n",
    "                try:\n",
    "                    print(home['full_address']['address'],home['full_address']['zip'])\n",
    "                    zillow_data = api.GetSearchResults(self.zillow_key, home['full_address']['address'],home['full_address']['zip'])\n",
    "                    z_data = {\n",
    "                        'address' : home['address'],\n",
    "                        'valuation_high' : zillow_data.zestimate.valuation_range_high,\n",
    "                     'zestimate' : zillow_data.zestimate.amount,\n",
    "                     'valuation_low' : zillow_data.zestimate.valuation_range_low,\n",
    "                     'zestimate_30_day_change' :zillow_data.zestimate.amount_change_30days,\n",
    "                     'details' : zillow_data.links.home_details,\n",
    "                     'overview_link':zillow_data.local_realestate.overview_link}\n",
    "                    print(z_data)\n",
    "                    self.cache_zillow['valuation_list'].append(z_data)\n",
    "                except:\n",
    "                    print('failed')\n",
    "        self.cache_zillow.dump()\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = pygsheets.authorize(client_secret='./client_secret_80237418460-ojb5d5fh62tiup3286i6vaejo715m6l9.apps.googleusercontent.com.json')\n",
    "sh = gc.open('zillow_properties')\n",
    "#select the first sheet \n",
    "wks = sh[0]\n",
    "\n",
    "addresses = wks.get_all_records()\n",
    "destination = 'Grand Central Terminal, New York, NY 10017'\n",
    "places = placesToLive(addresses,destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = places.get_district_data_from_name('New York City Geographic District #10','ny')\n",
    "places.cache_schools['district_data'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places.travel_related_values()\n",
    "places.get_school_district()\n",
    "places.update_zillow_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_to_transit_time = pd.DataFrame((places.cache['travel_to_transit_times']))\n",
    "travel_on_transit_time = pd.DataFrame((places.cache['travel_transit_times']))\n",
    "total_travel_time = travel_to_transit_time.merge(travel_on_transit_time,how='left',left_on=['public_transport_location'],right_on=['station_gps'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_travel_time['total_time'] = total_travel_time['duration_x'] + total_travel_time['duration_y']\n",
    "travel_time = total_travel_time.groupby(['house_address','type_of_transport_x']).agg({'total_time': ['min', 'max'],\n",
    "                                                                                      'duration_x' : ['min', 'max'],\n",
    "                                                                                      'duration_y' : ['min', 'max'],\n",
    "                                                                                     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_rank_history = pd.io.json.json_normalize(places.cache_schools['schools'],record_path=['school','rankHistory'],meta=['address',['school','districtID'],['school','districtName']])\n",
    "school_rankings = school_rank_history.groupby(['address','school.districtID','school.districtName']).agg({'rankStatewidePercentage':['min', 'max','mean']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow_data = pd.DataFrame(places.cache_zillow['valuation_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa =travel_time.reset_index().merge(school_rankings,how='left',left_on=['house_address'],right_on=['address'])\n",
    "bb = aa.merge(zillow_data,how='left',left_on=['house_address'],right_on=['address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewData=[]\n",
    "for grams in bb.columns:\n",
    "       NewData.append( (''.join([w+'-' for w in grams])).strip())\n",
    "NewData\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.columns = NewData\n",
    "wks_1 = sh[1]\n",
    "wks_1.set_dataframe(bb,(1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of simple unit tests\n",
    "test_station = ['300 Railroad Ave, Peekskill', ['train_station', 'transit_station', 'point_of_interest', 'establishment'], {'lat': 41.2850536, 'lng': -73.9308499}],['1 Croton Point Ave, Croton-On-Hudson', ['train_station', 'transit_station', 'point_of_interest', 'establishment'], {'lat': 41.1898375, 'lng': -73.88262929999999}],['1 Manitou Rd, Philipstown', ['train_station', 'transit_station', 'point_of_interest', 'establishment'], {'lat': 41.3326195, 'lng': -73.9704763}]\n",
    "print(get_time_of_travel('07:00',datetime.date(2019, 3, 23),1) == datetime.datetime(2019, 3, 31, 7, 0))\n",
    "print(lookup_nearest_stations((41.2548162, -73.9001377),5,'Train Station')[0][0] == '2 Memorial Drive, Cortlandt Manor')\n",
    "print(lookup_public_transit_travel_time(test_station,'Grand Central Terminal, New York, NY 10017',datetime.datetime(2019, 3, 28, 7, 0))[0]['distance']=='40.7 mi')\n",
    "print(lookup_travel_time_to_station('1 Croton Point Ave, Croton-On-Hudson,NY',test_station,datetime.datetime(2019, 3, 28, 7, 0),'driving')[0]['distance'] == '7.8 mi')\n",
    "print(convert_google_duration_to_minutes('3 days 2 hours and 15 minutes')==4455)\n",
    "print(convert_google_duration_to_minutes('2 hours and 15 minutes')==135)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg.extended_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home['zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gg = api.GetDeepSearchResults(zillow_key, home['address'],home['zip'])\n",
    "hh = api.GetDeepComps(zillow_key,zpid=gg.zpid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = gc.open('zillow_properties')\n",
    "#select the first sheet \n",
    "wks = sh[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = wks.get_as_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = gc.create('zillow_properties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(addresses)\n",
    "# Create a column\n",
    "\n",
    "#sh = gc.create('data Test',folder='NewYorkHouses')\n",
    "sh = gc.open('zillow_properties')\n",
    "\n",
    "#select the first sheet \n",
    "wks = sh[0]\n",
    "\n",
    "#update the first sheet with df, starting at cell B2. \n",
    "wks.set_dataframe(df,(1,1))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "best-place-to-live",
   "language": "python",
   "name": "best-place-to-live"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
